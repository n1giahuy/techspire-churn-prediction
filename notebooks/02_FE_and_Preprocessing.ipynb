{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5eafb1",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è **Notebook 02: Feature Engineering & Preprocessing**\n",
    "### **1. Overview**\n",
    "**Goal**: Prepare the raw data for machine learning models. In the previous EDA step, we identified issues like skewness, outliers, and class imbalance. In this notebook, we will fix those issues and construct new features to improve model performance.\n",
    "\n",
    "**Key Steps**:\n",
    "\n",
    "1. Cleaning & Dropping weak features.\n",
    "\n",
    "2. **Feature Construction**: Creating interaction terms.\n",
    "\n",
    "3. **Data Splitting**: Stratified Split to handle imbalance.\n",
    "\n",
    "4. **Transformations**: Log Transform (Skewness) & Winsorizing (Outliers).\n",
    "\n",
    "5. **Encoding**: Frequency Encoding for high-cardinality columns.\n",
    "\n",
    "6. **Scaling**: Standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938628cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "import sys \n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if '../src' not in sys.path: \n",
    "    sys.path.append('../src')\n",
    "import config \n",
    "import feature_engineering as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9753529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (50000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>reg_days</th>\n",
       "      <th>marketing_source</th>\n",
       "      <th>sessions_30d</th>\n",
       "      <th>sessions_90d</th>\n",
       "      <th>avg_session_duration_90d</th>\n",
       "      <th>median_pages_viewed_30d</th>\n",
       "      <th>...</th>\n",
       "      <th>support_tickets_2024</th>\n",
       "      <th>avg_csat_2024</th>\n",
       "      <th>emails_open_rate_90d</th>\n",
       "      <th>emails_click_rate_90d</th>\n",
       "      <th>review_count_2024</th>\n",
       "      <th>avg_review_stars_2024</th>\n",
       "      <th>rfm_recency</th>\n",
       "      <th>rfm_frequency</th>\n",
       "      <th>rfm_monetary</th>\n",
       "      <th>churn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U00001</td>\n",
       "      <td>20</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>262</td>\n",
       "      <td>ads_fb</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>728.93</td>\n",
       "      <td>4.41</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>80.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U00002</td>\n",
       "      <td>34</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>908</td>\n",
       "      <td>organic</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>671.11</td>\n",
       "      <td>7.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>49.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U00003</td>\n",
       "      <td>31</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>406</td>\n",
       "      <td>referral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>493.29</td>\n",
       "      <td>2.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "      <td>4.59</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>11.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U00004</td>\n",
       "      <td>23</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Johor Bahru</td>\n",
       "      <td>698</td>\n",
       "      <td>ads_fb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>305.83</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>14.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U00005</td>\n",
       "      <td>28</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>650</td>\n",
       "      <td>influencer</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>946.16</td>\n",
       "      <td>6.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1</td>\n",
       "      <td>4.79</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>116.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  age    country              city  reg_days marketing_source  \\\n",
       "0  U00001   20   Thailand           Bangkok       262           ads_fb   \n",
       "1  U00002   34  Indonesia           Jakarta       908          organic   \n",
       "2  U00003   31  Indonesia          Surabaya       406         referral   \n",
       "3  U00004   23   Malaysia       Johor Bahru       698           ads_fb   \n",
       "4  U00005   28    Vietnam  Ho Chi Minh City       650       influencer   \n",
       "\n",
       "   sessions_30d  sessions_90d  avg_session_duration_90d  \\\n",
       "0             2             4                    728.93   \n",
       "1             2             6                    671.11   \n",
       "2             0             3                    493.29   \n",
       "3             0             4                    305.83   \n",
       "4             1             7                    946.16   \n",
       "\n",
       "   median_pages_viewed_30d  ...  support_tickets_2024  avg_csat_2024  \\\n",
       "0                     4.41  ...                     1           4.30   \n",
       "1                     7.75  ...                     0           4.27   \n",
       "2                     2.58  ...                     0           4.35   \n",
       "3                     4.40  ...                     0           4.54   \n",
       "4                     6.04  ...                     0           4.04   \n",
       "\n",
       "  emails_open_rate_90d  emails_click_rate_90d  review_count_2024  \\\n",
       "0                0.252                  0.029                  0   \n",
       "1                0.388                  0.023                  0   \n",
       "2                0.343                  0.014                  0   \n",
       "3                0.270                  0.027                  0   \n",
       "4                0.212                  0.073                  1   \n",
       "\n",
       "   avg_review_stars_2024  rfm_recency  rfm_frequency  rfm_monetary  \\\n",
       "0                   4.46           55              4         80.58   \n",
       "1                   4.79           59              2         49.11   \n",
       "2                   4.59           73              1         11.95   \n",
       "3                   4.52           65              1         14.63   \n",
       "4                   4.79           68              5        116.32   \n",
       "\n",
       "   churn_label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(config.RAW_DATA_PATH)\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f8f1d",
   "metadata": {},
   "source": [
    "### **2. Dropping & Cleaning**\n",
    "\n",
    "**Description**: We start by removing columns that do not hold predictive value or might introduce noise:\n",
    "\n",
    "- `user_id`: Unique identifier (irrelevant for patterns).\n",
    "\n",
    "- `marketing_source` & `app_version`: Based on initial screening, these features showed weak correlation with Churn and added unnecessary complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78435315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping initial columns: ['user_id', 'marketing_source', 'app_version_major']\n",
      "Dropped ['user_id', 'marketing_source', 'app_version_major']\n",
      "Shape after dropping columns: (50000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dropping initial columns: {config.INITIAL_COLS_TO_DROP}\")\n",
    "df = fe.drop_weak_features(df, config.INITIAL_COLS_TO_DROP)\n",
    "print(f\"Shape after dropping columns: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63be71f",
   "metadata": {},
   "source": [
    "### **3. Feature Construction (Interaction Features)**\n",
    "\n",
    "**Description**: Sometimes, a combination of two features tells a better story than each one alone. We create \"Interaction Features\" based on business logic:\n",
    "\n",
    "- `satisfaction_x_recency`: Combines CSAT and Days Inactive. A user who is both unhappy and inactive is at much higher risk than a happy inactive user.\n",
    "\n",
    "- `gmv_per_session`: Acts as a proxy for \"Engagement Quality.\" It tells us how valuable each visit is, rather than just counting total visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acbc7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interaction features from Screening Round...\n",
      "Created interact features.\n",
      "Screening Round interaction features created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating interaction features from Screening Round...\")\n",
    "df = fe.create_interaction_features(df)\n",
    "print(\"Screening Round interaction features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccbd6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'country', 'city', 'reg_days', 'sessions_30d', 'sessions_90d', 'avg_session_duration_90d', 'median_pages_viewed_30d', 'search_queries_30d', 'device_mix_ratio', 'orders_30d', 'orders_90d', 'orders_2024', 'aov_2024', 'gmv_2024', 'category_diversity_2024', 'days_since_last_order', 'discount_rate_2024', 'refunds_count_2024', 'refund_rate_2024', 'support_tickets_2024', 'avg_csat_2024', 'emails_open_rate_90d', 'emails_click_rate_90d', 'review_count_2024', 'avg_review_stars_2024', 'rfm_recency', 'rfm_frequency', 'rfm_monetary', 'churn_label', 'satisfaction_x_recency', 'gmv_per_session_90d']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>reg_days</th>\n",
       "      <th>sessions_30d</th>\n",
       "      <th>sessions_90d</th>\n",
       "      <th>avg_session_duration_90d</th>\n",
       "      <th>median_pages_viewed_30d</th>\n",
       "      <th>search_queries_30d</th>\n",
       "      <th>device_mix_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>emails_open_rate_90d</th>\n",
       "      <th>emails_click_rate_90d</th>\n",
       "      <th>review_count_2024</th>\n",
       "      <th>avg_review_stars_2024</th>\n",
       "      <th>rfm_recency</th>\n",
       "      <th>rfm_frequency</th>\n",
       "      <th>rfm_monetary</th>\n",
       "      <th>churn_label</th>\n",
       "      <th>satisfaction_x_recency</th>\n",
       "      <th>gmv_per_session_90d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>262</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>728.93</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>80.58</td>\n",
       "      <td>0</td>\n",
       "      <td>236.50</td>\n",
       "      <td>16.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>908</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>671.11</td>\n",
       "      <td>7.75</td>\n",
       "      <td>8</td>\n",
       "      <td>0.897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>49.11</td>\n",
       "      <td>0</td>\n",
       "      <td>251.93</td>\n",
       "      <td>7.015714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>493.29</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "      <td>4.59</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>11.95</td>\n",
       "      <td>1</td>\n",
       "      <td>317.55</td>\n",
       "      <td>2.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Johor Bahru</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>305.83</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>14.63</td>\n",
       "      <td>1</td>\n",
       "      <td>295.10</td>\n",
       "      <td>2.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>946.16</td>\n",
       "      <td>6.04</td>\n",
       "      <td>8</td>\n",
       "      <td>0.511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1</td>\n",
       "      <td>4.79</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>116.32</td>\n",
       "      <td>1</td>\n",
       "      <td>274.72</td>\n",
       "      <td>14.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age    country              city  reg_days  sessions_30d  sessions_90d  \\\n",
       "0   20   Thailand           Bangkok       262             2             4   \n",
       "1   34  Indonesia           Jakarta       908             2             6   \n",
       "2   31  Indonesia          Surabaya       406             0             3   \n",
       "3   23   Malaysia       Johor Bahru       698             0             4   \n",
       "4   28    Vietnam  Ho Chi Minh City       650             1             7   \n",
       "\n",
       "   avg_session_duration_90d  median_pages_viewed_30d  search_queries_30d  \\\n",
       "0                    728.93                     4.41                   1   \n",
       "1                    671.11                     7.75                   8   \n",
       "2                    493.29                     2.58                   1   \n",
       "3                    305.83                     4.40                   4   \n",
       "4                    946.16                     6.04                   8   \n",
       "\n",
       "   device_mix_ratio  ...  emails_open_rate_90d  emails_click_rate_90d  \\\n",
       "0             0.861  ...                 0.252                  0.029   \n",
       "1             0.897  ...                 0.388                  0.023   \n",
       "2             0.917  ...                 0.343                  0.014   \n",
       "3             0.840  ...                 0.270                  0.027   \n",
       "4             0.511  ...                 0.212                  0.073   \n",
       "\n",
       "   review_count_2024  avg_review_stars_2024  rfm_recency  rfm_frequency  \\\n",
       "0                  0                   4.46           55              4   \n",
       "1                  0                   4.79           59              2   \n",
       "2                  0                   4.59           73              1   \n",
       "3                  0                   4.52           65              1   \n",
       "4                  1                   4.79           68              5   \n",
       "\n",
       "   rfm_monetary  churn_label  satisfaction_x_recency  gmv_per_session_90d  \n",
       "0         80.58            0                  236.50            16.116000  \n",
       "1         49.11            0                  251.93             7.015714  \n",
       "2         11.95            1                  317.55             2.987500  \n",
       "3         14.63            1                  295.10             2.926000  \n",
       "4        116.32            1                  274.72            14.540000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fde3ef",
   "metadata": {},
   "source": [
    "### **4. Stratified Train-Test Split**\n",
    "\n",
    "**Description**: This is a critical step. We split the data into Train (65%), Validation (15%), and Test (20%).\n",
    "\n",
    "- **Why Stratify?** Since our Churn rate is 25% (imbalanced), using `stratify=y` ensures that every subset maintains this exact 75:25 ratio.\n",
    "\n",
    "- **Prevention**: This prevents \"Data Leakage\" and ensures our evaluation metrics are reliable later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9fe457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (40000, 31)\n",
      "X_test shape: (10000, 31)\n",
      "Churn rate in y_train_full: 0.2500\n",
      "Churn rate in y_test: 0.2500\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[config.TARGET_VARIABLE])\n",
    "y = df[config.TARGET_VARIABLE]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=config.TEST_SET_SIZE,\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    stratify=y \n",
    ")\n",
    "\n",
    "print(f\"X_train_full shape: {X_train_full.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Churn rate in y_train_full: {y_train_full.mean():.4f}\")\n",
    "print(f\"Churn rate in y_test: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cc7137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32500, 31) (~65%)\n",
      "X_val shape: (7500, 31) (~15%)\n",
      "X_test shape: (10000, 31) (~20%)\n",
      "\n",
      "Churn rate in y_train: 0.2500\n",
      "Churn rate in y_val: 0.2500\n",
      "Churn rate in y_test: 0.2500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=config.VALIDATION_SET_SIZE, \n",
    "    random_state=config.RANDOM_STATE,\n",
    "    stratify=y_train_full \n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} (~65%)\")\n",
    "print(f\"X_val shape: {X_val.shape} (~15%)\")\n",
    "print(f\"X_test shape: {X_test.shape} (~20%)\")\n",
    "print(f\"\\nChurn rate in y_train: {y_train.mean():.4f}\")\n",
    "print(f\"Churn rate in y_val: {y_val.mean():.4f}\")\n",
    "print(f\"Churn rate in y_test: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca138a",
   "metadata": {},
   "source": [
    "### **5. Handling Skewness (Log Transformation)**\n",
    "\n",
    "**Description**: As seen in the EDA histograms, financial features like `gmv_2024` and `sessions_90d` have a \"Long Tail\" (right-skewed).\n",
    "\n",
    "- **Technique**: We apply `np.log1p` (Log + 1).\n",
    "\n",
    "- **Effect**: This compresses the large values, making the distribution more \"Normal\" (Gaussian-like). This helps linear models (like Logistic Regression) perform significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26ab86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying log transformation to: ['gmv_2024', 'sessions_90d']\n",
      "Skewness handled.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Applying log transformation to: {config.COLS_TO_LOG_TRANSFORM}\")\n",
    "X_train = fe.handle_skewness(X_train.copy(), config.COLS_TO_LOG_TRANSFORM)\n",
    "X_val = fe.handle_skewness(X_val.copy(), config.COLS_TO_LOG_TRANSFORM)\n",
    "X_test = fe.handle_skewness(X_test.copy(), config.COLS_TO_LOG_TRANSFORM)\n",
    "print(\"Skewness handled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba953a",
   "metadata": {},
   "source": [
    "### **6. Outlier Handling (Winsorizing)**\n",
    "\n",
    "**Description**: We have extreme values in `days_since_last_order` and spending.\n",
    "\n",
    "- **Technique**: Instead of deleting these rows (which loses information), we use Winsorizing. We cap values at the 1st and 99th percentiles.\n",
    "\n",
    "- **Benefit**: This keeps the data points but prevents extreme outliers from distorting the model's weights / gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005727c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling outliers for 17 numerical columns...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers handled using Winsorizing.\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [col for col in config.NUMERICAL_COLS_FOR_OUTLIERS if col in X_train.columns]\n",
    "print(f\"\\nHandling outliers for {len(numerical_cols)} numerical columns...\")\n",
    "X_train = fe.handle_outliers(X_train.copy(), numerical_cols)\n",
    "X_val = fe.handle_outliers(X_val.copy(), numerical_cols)\n",
    "X_test = fe.handle_outliers(X_test.copy(), numerical_cols)\n",
    "print(\"Outliers handled using Winsorizing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27f11f",
   "metadata": {},
   "source": [
    "### **7. Categorical Encoding**\n",
    "\n",
    "**Description**: Columns like country and city have many unique values (High Cardinality).\n",
    "\n",
    "- **Why not One-Hot?** One-Hot Encoding would create hundreds of new columns, causing the \"Curse of Dimensionality.\"\n",
    "\n",
    "- **Solution**: We use **Frequency Encoding**. We replace the city name with the percentage of times it appears in the dataset. This preserves the information density without expanding the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553fc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Frequency Encoding to: ['country', 'city']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded.\n",
      "Final columns after encoding: ['age', 'reg_days', 'sessions_30d', 'sessions_90d', 'avg_session_duration_90d', 'median_pages_viewed_30d', 'search_queries_30d', 'device_mix_ratio', 'orders_30d', 'orders_90d', 'orders_2024', 'aov_2024', 'gmv_2024', 'category_diversity_2024', 'days_since_last_order', 'discount_rate_2024', 'refunds_count_2024', 'refund_rate_2024', 'support_tickets_2024', 'avg_csat_2024', 'emails_open_rate_90d', 'emails_click_rate_90d', 'review_count_2024', 'avg_review_stars_2024', 'rfm_recency', 'rfm_frequency', 'rfm_monetary', 'satisfaction_x_recency', 'gmv_per_session_90d', 'country_freq', 'city_freq']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nApplying Frequency Encoding to: {config.HIGH_CARDINALITY_COLS}\")\n",
    "X_train, X_val, X_test = fe.encode_categorical_features(\n",
    "    X_train.copy(), X_val.copy(), X_test.copy(), config.HIGH_CARDINALITY_COLS\n",
    ")\n",
    "print(\"Categorical features encoded.\")\n",
    "print(\"Final columns after encoding:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0fc4f",
   "metadata": {},
   "source": [
    "### **8. Feature Scaling**\n",
    "\n",
    "**Description**: Different features have different ranges (e.g., Age is 18-80, GMV is 0-10,000).\n",
    "\n",
    "- **Technique**: We use `StandardScaler` to shift distributions to have Mean = 0 and Variance = 1.\n",
    "\n",
    "- **Important**: We `fit` the scaler ONLY on the Training set, and then transform Validation/Test sets. This strictly prevents data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e1b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features scaled successfully.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "print(\"Numerical features scaled successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32f1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to: ../data/processed/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "scaler_path = os.path.join(config.PROCESSED_DATA_PATH, 'scaler.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"Scaler saved to: {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efd57180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed data artifacts have been saved to: ../data/processed/\n",
      "Files in processed data directory: ['scaler.pkl', 'X_test.csv', 'X_train.csv', 'X_val.csv', 'y_test.csv', 'y_train.csv', 'y_val.csv']\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(config.PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "X_train.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'X_train.csv'), index=False)\n",
    "X_val.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'X_val.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'X_test.csv'), index=False)\n",
    "\n",
    "y_train.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'y_train.csv'), index=False, header=True)\n",
    "y_val.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'y_val.csv'), index=False, header=True)\n",
    "y_test.to_csv(os.path.join(config.PROCESSED_DATA_PATH, 'y_test.csv'), index=False, header=True)\n",
    "\n",
    "print(\"All processed data artifacts have been saved to:\", config.PROCESSED_DATA_PATH)\n",
    "print(\"Files in processed data directory:\", os.listdir(config.PROCESSED_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33be5e",
   "metadata": {},
   "source": [
    "# üìù **Summary**\n",
    "\n",
    "**Conclusion:**\n",
    "We have successfully transformed the raw, messy data into a clean, numerical format ready for machine learning algorithms.\n",
    "\n",
    "**Key Achievements:**\n",
    "\n",
    "1. **Addressed Data Quality:** Skewness and outliers have been handled using Log Transformation and Winsorizing, ensuring our model isn't confused by extreme values.\n",
    "2. **Enriched Information:** New interaction features (e.g., `satisfaction_x_recency`) have been created to capture complex user behaviors that single features might miss.\n",
    "3. **Prevented Leakage:** The train/val/test split was performed *before* any scaling or encoding to ensure the validity of our evaluation.\n",
    "4. **Ready for Training:** All categorical variables are encoded, and numericals are scaled.\n",
    "\n",
    "The processed datasets (`X_train`, `y_train`, etc.) and the `scaler` object have been saved to the `../data/processed/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huyy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
